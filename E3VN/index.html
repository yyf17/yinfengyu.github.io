<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">

    <title>SAAVN</title>
  </head>
  <body>
  	<div style="text-align:center;">
		<div id="intro" style="width: 100%; padding:40px; text-align:center;">
	        <h1>Echo-Enhanced Embodied Visual Navigation</h1>
        </div>
		<div class="container">
		  <div class="row">
		    <div class="col-sm">
		      <a href="https://yyf17.github.io/"><h4> Yinfeng Yu </h4></a>    
		    </div>
		    <div class="col-sm">
		      <a href=""><h4> Lele Cao</h4></a> 
		    </div>
		    <div class="col-sm">
		      <a href=""><h4> Fuchun Sun</h4></a> 
		    </div>
		    <div class="col-sm">
		      <a ><h4> Chao Yang </h4></a> 
            </div>
            <div class="col-sm">
                <a href=""><h4> Huicheng Lai </h4></a> 
            </div>
            <div class="col-sm">
                <a href=""><h4> Wenbing Huang </h4></a> 
            </div>
		  </div>
		  <p></p>
		  <div class="row">
		  	<div class="col-lg">
		   	<h4>  Tsinghua University (THU) </h4>
		    </div>
		  </div>
		  <div class="row">
		  	<div class="col-lg">
		   	<h4> Neural Computation (2023) </h4>
		    </div>
		  </div>
		  
		  <div class="row">
		  			    <div class="col-lg">
		    <center><h2><strong>
	<a href="https://direct.mit.edu/neco/article-pdf/35/5/958/2079357/neco_a_01579.pdf">Paper</a> |
    <a href="./files/bib.txt">Bibtex</a> </strong> </h2></center> 
			</div>
		  </div>
		  <br>
		  
		  <div class="row">
		  	<div class="col-lg">
		  	<img src="./files/saavn.png" class="img-fluid" style="height:215px;">
		  	</div>
		  </div>

		  <br><br>
		  <div class="row">
		  	<div class="col-sm">
		  		<h2> Abstract </h2>
		  	</div>
		  </div>
		  <div class="row">
		  	<div style="font-size:16px"><p align="justify">
                Visual navigation involves a movable robotic agent striving to reach a point goal (target location) using vision sensory input. While navigation with ideal visibility has seen plenty of success, it becomes challenging in suboptimal visual conditions like poor illumination, where traditional approaches suffer from severe performance degradation. We propose E3VN (echo-enhanced embodied visual navigation) to effectively perceive the surroundings even under poor visibility to mitigate this problem. This is made possible by adopting an echoer that actively perceives the environment via auditory signals. E3VN models the robot agent as playing a cooperative Markov game with that echoer. The action policies of robot and echoer are jointly optimized to maximize the reward in a two-stream actor-critic architecture. During optimization, the reward is also adaptively decomposed into the robot and echoer parts. Our experiments and ablation studies show that E3VN is consistently effective and robust in point goal navigation tasks, especially under nonideal visibility.
		  	</p>
		  	</div>
		  </div>

		  <br><br>


		  <div class="row">
		  	<div class="col-sm">
		  		<h2> Citation </h2>
		  		    <pre align="left">
                            @article{10.1162/neco_a_01579,
                                author = {Yu, Yinfeng and Cao, Lele and Sun, Fuchun and Yang, Chao and Lai, Huicheng and Huang, Wenbing},
                                title = {Echo-Enhanced Embodied Visual Navigation},
                                journal = {Neural Computation},
                                volume = {35},
                                number = {5},
                                pages = {958-976},
                                year = {2023},
                                month = {04},
                                issn = {0899-7667},
                                doi = {10.1162/neco_a_01579},
                                url = {https://doi.org/10.1162/neco\_a\_01579},
                                eprint = {https://direct.mit.edu/neco/article-pdf/35/5/958/2079357/neco\_a\_01579.pdf},
                            }
                    </pre>
			</div>
		  </div>

		  <div class="row">
		  	<div class="col-sm">
		  		<h2> Acknowledgement </h2>
		  		<p align="left">
	                This work is funded by Sino-German Collaborative Research Project Crossmodal Learn-
ing with identification number NSFC62061136001/DFG SFB/TRR169.
            <br><br>
		  	</div>
		  </div>		  

		</div>
	</div>



	<div id="intro" style="width: 100%; padding:50px; text-align:center;">
	        <h1></h1>
	</div>

    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx" crossorigin="anonymous"></script>
   
  </body>
</html>
